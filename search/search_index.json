{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to MkDocs For full documentation visit mkdocs.org . Commands mkdocs new [dir-name] - Create a new project. mkdocs serve - Start the live-reloading docs server. mkdocs build - Build the documentation site. mkdocs help - Print this help message. Project layout mkdocs.yml # The configuration file. docs/ index.md # The documentation homepage. ... # Other markdown pages, images and other files. from __future__ import print_function import keras from keras.datasets import mnist from keras.models import Sequential from keras.layers import Dense, Dropout, Flatten from keras.layers import Conv2D, MaxPooling2D from keras import backend as K batch_size = 128 num_classes = 10 epochs = 12 # input image dimensions img_rows, img_cols = 28, 28 # the data, split between train and test sets (x_train, y_train), (x_test, y_test) = mnist.load_data() if K.image_data_format() == 'channels_first': x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols) x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols) input_shape = (1, img_rows, img_cols) else: x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1) x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1) input_shape = (img_rows, img_cols, 1) x_train = x_train.astype('float32') x_test = x_test.astype('float32') x_train /= 255 x_test /= 255 print('x_train shape:', x_train.shape) print(x_train.shape[0], 'train samples') print(x_test.shape[0], 'test samples') # convert class vectors to binary class matrices y_train = keras.utils.to_categorical(y_train, num_classes) y_test = keras.utils.to_categorical(y_test, num_classes) model = Sequential() model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape)) model.add(Conv2D(64, (3, 3), activation='relu')) model.add(MaxPooling2D(pool_size=(2, 2))) model.add(Dropout(0.25)) model.add(Flatten()) model.add(Dense(128, activation='relu')) model.add(Dropout(0.5)) model.add(Dense(num_classes, activation='softmax')) model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adadelta(), metrics=['accuracy']) model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_test, y_test)) score = model.evaluate(x_test, y_test, verbose=0) print('Test loss:', score[0]) print('Test accuracy:', score[1])","title":"Welcome to MkDocs"},{"location":"#welcome-to-mkdocs","text":"For full documentation visit mkdocs.org .","title":"Welcome to MkDocs"},{"location":"#commands","text":"mkdocs new [dir-name] - Create a new project. mkdocs serve - Start the live-reloading docs server. mkdocs build - Build the documentation site. mkdocs help - Print this help message.","title":"Commands"},{"location":"#project-layout","text":"mkdocs.yml # The configuration file. docs/ index.md # The documentation homepage. ... # Other markdown pages, images and other files. from __future__ import print_function import keras from keras.datasets import mnist from keras.models import Sequential from keras.layers import Dense, Dropout, Flatten from keras.layers import Conv2D, MaxPooling2D from keras import backend as K batch_size = 128 num_classes = 10 epochs = 12 # input image dimensions img_rows, img_cols = 28, 28 # the data, split between train and test sets (x_train, y_train), (x_test, y_test) = mnist.load_data() if K.image_data_format() == 'channels_first': x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols) x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols) input_shape = (1, img_rows, img_cols) else: x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1) x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1) input_shape = (img_rows, img_cols, 1) x_train = x_train.astype('float32') x_test = x_test.astype('float32') x_train /= 255 x_test /= 255 print('x_train shape:', x_train.shape) print(x_train.shape[0], 'train samples') print(x_test.shape[0], 'test samples') # convert class vectors to binary class matrices y_train = keras.utils.to_categorical(y_train, num_classes) y_test = keras.utils.to_categorical(y_test, num_classes) model = Sequential() model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape)) model.add(Conv2D(64, (3, 3), activation='relu')) model.add(MaxPooling2D(pool_size=(2, 2))) model.add(Dropout(0.25)) model.add(Flatten()) model.add(Dense(128, activation='relu')) model.add(Dropout(0.5)) model.add(Dense(num_classes, activation='softmax')) model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adadelta(), metrics=['accuracy']) model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_test, y_test)) score = model.evaluate(x_test, y_test, verbose=0) print('Test loss:', score[0]) print('Test accuracy:', score[1])","title":"Project layout"},{"location":"C++ & Algorithm/","text":"C++ & Algorithm Date : 2019/11/21 hello world!","title":"C++ & Algorithm"},{"location":"C++ & Algorithm/#c-algorithm","text":"Date : 2019/11/21","title":"C++ &amp; Algorithm"},{"location":"C++ & Algorithm/#hello-world","text":"","title":"hello world!"},{"location":"C++ & Algorithm/c++ iterator/","text":"c++ iterator Date : 2019/11/18 Ref : eehoeskrap \ube14\ub85c\uadf8 tcpschool \ubc18\ubcf5\uc790\ub780? STL \ucee8\ud14c\uc774\ub108\uc5d0 \uc800\uc7a5\ub41c \uc694\uc18c\ub97c \ubc18\ubcf5\uc801\uc73c\ub85c \uc21c\ud68c\ud558\uc5ec, \uac01\uac01\uc758 \uc694\uc18c\uc5d0 \ub300\ud55c \uc811\uadfc\uc744 \uc81c\uacf5\ud558\ub294 \uac1d\uccb4\ub2e4. \ubc18\ubcf5\uc790\uc758 \uc885\ub958 \ubc18\ubcf5\uc790 \uc885\ub958 \uc0ac\uc6a9 \ubc29\uc2dd \uc785\ub825 \ubc18\ubcf5\uc790 (input iterator) istream_iterator \ucd9c\ub825 \ubc18\ubcf5\uc790 (output iterator) ostream_iterator inserter front_inserter back_inserter \uc21c\ubc29\ud5a5 \ubc18\ubcf5\uc790 (forward iterator) \uc591\ubc29\ud5a5 \ubc18\ubcf5\uc790 (bidirectional iterator) list set \uacfc multiset map \uacfc multimap \uc784\uc758\uc811\uadfc \ubc18\ubcf5\uc790 (random access iterator) \uc77c\ubc18 \ud3ec\uc778\ud130 vector deque \ubc18\ubcf5\uc790\uc758 \uc5ed\ud560 \ubc18\ubcf5\uc790 \uc885\ub958 \uc77d\uae30 \uc811\uadfc \uc4f0\uae30 \uc99d\uac10 \ube44\uad50 \uc785\ub825 \ubc18\ubcf5\uc790 (input iterator) =*p -> ++ == != \ucd9c\ub825 \ubc18\ubcf5\uc790 (output iterator) *p= ++ \uc21c\ubc29\ud5a5 \ubc18\ubcf5\uc790 (forward iterator) =*p -> *p= ++ == != \uc591\ubc29\ud5a5 \ubc18\ubcf5\uc790 (bidirectional iterator) =*p -> *p= ++ -- == != \uc784\uc758\uc811\uadfc \ubc18\ubcf5\uc790 (random access iterator) =*p -> [] *p= ++ -- + - += -= == != < > <= >= \ud45c\ub294 eehoeskrap \ube14\ub85c\uadf8 \uc5d0\uc11c \ubc1c\ucdcc\ud588\ub2e4.","title":"C++ iterator"},{"location":"C++ & Algorithm/c++ iterator/#c-iterator","text":"Date : 2019/11/18 Ref : eehoeskrap \ube14\ub85c\uadf8 tcpschool","title":"c++ iterator"},{"location":"C++ & Algorithm/c++ iterator/#_1","text":"STL \ucee8\ud14c\uc774\ub108\uc5d0 \uc800\uc7a5\ub41c \uc694\uc18c\ub97c \ubc18\ubcf5\uc801\uc73c\ub85c \uc21c\ud68c\ud558\uc5ec, \uac01\uac01\uc758 \uc694\uc18c\uc5d0 \ub300\ud55c \uc811\uadfc\uc744 \uc81c\uacf5\ud558\ub294 \uac1d\uccb4\ub2e4.","title":"\ubc18\ubcf5\uc790\ub780?"},{"location":"C++ & Algorithm/c++ iterator/#_2","text":"\ubc18\ubcf5\uc790 \uc885\ub958 \uc0ac\uc6a9 \ubc29\uc2dd \uc785\ub825 \ubc18\ubcf5\uc790 (input iterator) istream_iterator \ucd9c\ub825 \ubc18\ubcf5\uc790 (output iterator) ostream_iterator inserter front_inserter back_inserter \uc21c\ubc29\ud5a5 \ubc18\ubcf5\uc790 (forward iterator) \uc591\ubc29\ud5a5 \ubc18\ubcf5\uc790 (bidirectional iterator) list set \uacfc multiset map \uacfc multimap \uc784\uc758\uc811\uadfc \ubc18\ubcf5\uc790 (random access iterator) \uc77c\ubc18 \ud3ec\uc778\ud130 vector deque","title":"\ubc18\ubcf5\uc790\uc758 \uc885\ub958"},{"location":"C++ & Algorithm/c++ iterator/#_3","text":"\ubc18\ubcf5\uc790 \uc885\ub958 \uc77d\uae30 \uc811\uadfc \uc4f0\uae30 \uc99d\uac10 \ube44\uad50 \uc785\ub825 \ubc18\ubcf5\uc790 (input iterator) =*p -> ++ == != \ucd9c\ub825 \ubc18\ubcf5\uc790 (output iterator) *p= ++ \uc21c\ubc29\ud5a5 \ubc18\ubcf5\uc790 (forward iterator) =*p -> *p= ++ == != \uc591\ubc29\ud5a5 \ubc18\ubcf5\uc790 (bidirectional iterator) =*p -> *p= ++ -- == != \uc784\uc758\uc811\uadfc \ubc18\ubcf5\uc790 (random access iterator) =*p -> [] *p= ++ -- + - += -= == != < > <= >= \ud45c\ub294 eehoeskrap \ube14\ub85c\uadf8 \uc5d0\uc11c \ubc1c\ucdcc\ud588\ub2e4.","title":"\ubc18\ubcf5\uc790\uc758 \uc5ed\ud560"},{"location":"C++ & Algorithm/c++ vector/","text":"c++ vector Date : 2019/11/18 Ref : blockdmask \ube14\ub85c\uadf8 header #include <iostream> #include <vector> #include <algorithm> using namespace std; \ud6c4\uc5d0 \ubca1\ud130\uc640 \uc815\ub82c\ub4f1\uc758 \uc54c\uace0\ub9ac\uc998\uc744 \uc0ac\uc6a9\ud560 \uc608\uc815\uc774\uc5b4\uc11c vector\uc640 algorithm\ud5e4\ub354\ub97c \uac00\uc838\uc640\uc900\ub2e4. vector init vector<int> v; // \ube44\uc5b4\uc788\ub294 int \ud615 vector v\ub97c \uc120\uc5b8 vector<int> v(5); // 0\uc73c\ub85c \ucd08\uae30\ud654 \ub41c 5\uac1c\uc758 \uc6d0\uc18c\ub97c \uac00\uc9c0\ub294 int \ud615 vector v\ub97c \uc120\uc5b8 vector<int> v(5, 2); // 2\ub85c \ucd08\uae30\ud654 \ub41c 5\uac1c\uc758 \uc6d0\uc18c\ub97c \uac00\uc9c0\ub294 int \ud615 vector v\ub97c \uc120\uc5b8 \uc774\ud6c4 \ucd9c\ub825\ud574\ubcf4\uba74 \ub2e4\uc74c\uacfc \uac19\ub2e4. vector<int> vec1(5); for (auto it : vec1){ cout << it << \" \"; } cout << endl; # 0 0 0 0 0 vector<int> vec2(5, 2); for (auto it : vec2){ cout << it << \" \"; } cout << endl; # 2 2 2 2 2 vector<int> vec3(vec2); for (auto it : vec3){ cout << it << \" \"; } # 2 2 2 2 2 vector function assign : \uc6d0\uc18c \ud560\ub2f9(\ucd08\uae30\ud654) vector<int> vec(3,1); for (auto it : vec){ cout << it << \" \"; } cout << endl; # 1 1 1 vec.assign(5, 2); for (auto it : vec){ cout << it << \" \"; } # 2 2 2 2 2 at : \uc6d0\uc18c \ucc38\uc870 vector<int> vec; vec.push_back(1); vec.push_back(2); vec.push_back(3); cout << vec.at(2) << endl; # 3 \ubc94\uc704\ub97c \uc810\uac80\ud574\uc11c \uc548\uc804\ud558\uace0 \ub290\ub9ac\ub2e4. cout << vec[2] << endl; # 3 \uc704\ud5d8\ud558\uace0 \ube60\ub974\ub2e4. front() : \uac00\uc7a5 \uc55e\uc758 \uc6d0\uc18c\ub97c \uac00\uc838\uc628\ub2e4. end() : \uac00\uc7a5 \ub4a4\uc758 \uc6d0\uc18c\ub97c \uac00\uc838\uc628\ub2e4. vector<int> vec; vec.push_back(1); vec.push_back(2); vec.push_back(3); cout << vec.front() << \" \" << vec.back() << endl; # 1 3 push_back() : \uc6d0\uc18c\ub97c \ub4a4\uc5d0\uc11c \uc0bd\uc785\ud55c\ub2e4. pop_back() : \uc6d0\uc18c\ub97c \ub4a4\uc5d0\uc11c \uc81c\uac70\ud55c\ub2e4. vector<int> vec; vec.push_back(1); vec.push_back(2); vec.push_back(3); vec.push_back(7); cout << vec.back() << \" \"; # 7 vec.pop_back(); cout << vec.back() << \" \"; # 3 vec.begin() : \uccab \ubc88\uc9f8 \uc6d0\uc18c\ub97c \uac00\ub9ac\ud0a8\ub2e4. ( iterator ) vec.end() : \ub9c8\uc9c0\ub9c9\uc758 \ub2e4\uc74c \uc6d0\uc18c\ub97c \uac00\ub9ac\ud0a8\ub2e4. ( iterator ) algorithm\uc758 sort\ub97c \uc774\uc6a9\ud55c \uc815\ub82c vector<int> vec; vec.push_back(3); vec.push_back(2); vec.push_back(5); vec.push_back(1); sort(vec.begin(), vec.end()); for (auto it : vec){ cout << it << \" \"; } \ub0b4\ub9bc\ucc28\uc21c \uc815\ub82c #include <functional> int main(){ vector<int> vec; vec.push_back(3); vec.push_back(2); vec.push_back(5); vec.push_back(1); sort(vec.begin(), vec.end(), greater<int>()); for (auto it : vec){ cout << it << \" \"; } } # 5 3 2 1 greater\uc0ac\uc6a9\uc744 \uc704\ud574 functional\ud5e4\ub354\ub97c \uac00\uc838\uc628\ub2e4.","title":"C++ vector"},{"location":"C++ & Algorithm/c++ vector/#c-vector","text":"Date : 2019/11/18 Ref : blockdmask \ube14\ub85c\uadf8","title":"c++ vector"},{"location":"C++ & Algorithm/c++ vector/#header","text":"#include <iostream> #include <vector> #include <algorithm> using namespace std; \ud6c4\uc5d0 \ubca1\ud130\uc640 \uc815\ub82c\ub4f1\uc758 \uc54c\uace0\ub9ac\uc998\uc744 \uc0ac\uc6a9\ud560 \uc608\uc815\uc774\uc5b4\uc11c vector\uc640 algorithm\ud5e4\ub354\ub97c \uac00\uc838\uc640\uc900\ub2e4.","title":"header"},{"location":"C++ & Algorithm/c++ vector/#vector-init","text":"vector<int> v; // \ube44\uc5b4\uc788\ub294 int \ud615 vector v\ub97c \uc120\uc5b8 vector<int> v(5); // 0\uc73c\ub85c \ucd08\uae30\ud654 \ub41c 5\uac1c\uc758 \uc6d0\uc18c\ub97c \uac00\uc9c0\ub294 int \ud615 vector v\ub97c \uc120\uc5b8 vector<int> v(5, 2); // 2\ub85c \ucd08\uae30\ud654 \ub41c 5\uac1c\uc758 \uc6d0\uc18c\ub97c \uac00\uc9c0\ub294 int \ud615 vector v\ub97c \uc120\uc5b8 \uc774\ud6c4 \ucd9c\ub825\ud574\ubcf4\uba74 \ub2e4\uc74c\uacfc \uac19\ub2e4. vector<int> vec1(5); for (auto it : vec1){ cout << it << \" \"; } cout << endl; # 0 0 0 0 0 vector<int> vec2(5, 2); for (auto it : vec2){ cout << it << \" \"; } cout << endl; # 2 2 2 2 2 vector<int> vec3(vec2); for (auto it : vec3){ cout << it << \" \"; } # 2 2 2 2 2","title":"vector init"},{"location":"C++ & Algorithm/c++ vector/#vector-function","text":"assign : \uc6d0\uc18c \ud560\ub2f9(\ucd08\uae30\ud654) vector<int> vec(3,1); for (auto it : vec){ cout << it << \" \"; } cout << endl; # 1 1 1 vec.assign(5, 2); for (auto it : vec){ cout << it << \" \"; } # 2 2 2 2 2 at : \uc6d0\uc18c \ucc38\uc870 vector<int> vec; vec.push_back(1); vec.push_back(2); vec.push_back(3); cout << vec.at(2) << endl; # 3 \ubc94\uc704\ub97c \uc810\uac80\ud574\uc11c \uc548\uc804\ud558\uace0 \ub290\ub9ac\ub2e4. cout << vec[2] << endl; # 3 \uc704\ud5d8\ud558\uace0 \ube60\ub974\ub2e4. front() : \uac00\uc7a5 \uc55e\uc758 \uc6d0\uc18c\ub97c \uac00\uc838\uc628\ub2e4. end() : \uac00\uc7a5 \ub4a4\uc758 \uc6d0\uc18c\ub97c \uac00\uc838\uc628\ub2e4. vector<int> vec; vec.push_back(1); vec.push_back(2); vec.push_back(3); cout << vec.front() << \" \" << vec.back() << endl; # 1 3 push_back() : \uc6d0\uc18c\ub97c \ub4a4\uc5d0\uc11c \uc0bd\uc785\ud55c\ub2e4. pop_back() : \uc6d0\uc18c\ub97c \ub4a4\uc5d0\uc11c \uc81c\uac70\ud55c\ub2e4. vector<int> vec; vec.push_back(1); vec.push_back(2); vec.push_back(3); vec.push_back(7); cout << vec.back() << \" \"; # 7 vec.pop_back(); cout << vec.back() << \" \"; # 3 vec.begin() : \uccab \ubc88\uc9f8 \uc6d0\uc18c\ub97c \uac00\ub9ac\ud0a8\ub2e4. ( iterator ) vec.end() : \ub9c8\uc9c0\ub9c9\uc758 \ub2e4\uc74c \uc6d0\uc18c\ub97c \uac00\ub9ac\ud0a8\ub2e4. ( iterator ) algorithm\uc758 sort\ub97c \uc774\uc6a9\ud55c \uc815\ub82c vector<int> vec; vec.push_back(3); vec.push_back(2); vec.push_back(5); vec.push_back(1); sort(vec.begin(), vec.end()); for (auto it : vec){ cout << it << \" \"; } \ub0b4\ub9bc\ucc28\uc21c \uc815\ub82c #include <functional> int main(){ vector<int> vec; vec.push_back(3); vec.push_back(2); vec.push_back(5); vec.push_back(1); sort(vec.begin(), vec.end(), greater<int>()); for (auto it : vec){ cout << it << \" \"; } } # 5 3 2 1 greater\uc0ac\uc6a9\uc744 \uc704\ud574 functional\ud5e4\ub354\ub97c \uac00\uc838\uc628\ub2e4.","title":"vector function"},{"location":"deeplearning/Functional Api & Y-Network with Keras/","text":"Functional Api & Y-Network with Keras Date : 2019/11/17 Ref : \ucf00\ub77c\uc2a4\ub85c \uad6c\ud604\ud558\ub294 \uace0\uae09 \ub525\ub7ec\ub2dd \uc54c\uace0\ub9ac\uc998 [chapter 2] functional api input\ub808\uc774\uc5b4\ub97c \ub530\ub85c \uac00\uc838\uc640\uc900\ub2e4. from keras.layers import Input \uc21c\ucc28\ud615\uacfc\ub294 \ucf54\ub4dc\uac00 \uc870\uae08\uc529 \ub2e4\ub974\ub2e4. \ud6c4\uc5d0 \ud655\uc7a5\uc131\uc744 \uace0\ub824\ud558\uc5ec \ud568\uc218\ud615\uc73c\ub85c \ucf00\ub77c\uc2a4 \ubaa8\ub378\uc744 \ub9cc\ub4dc\ub294 \uc5f0\uc2b5\uc744 \ud558\uc790. inputs = Input(shape=input_shape) y = Conv2D(filters=filters, kernel_size=kernel_size, activation='relu')(inputs) y = MaxPooling2D()(y) y = Conv2D(filters=filters, kernel_size=kernel_size, activation='relu')(y) y = MaxPooling2D()(y) y = Conv2D(filters=filters, kernel_size=kernel_size, activation='relu')(y) y = Flatten()(y) y = Dropout(dropout)(y) outputs = Dense(num_labels, activation='softmax')(y) model = Model(inputs=inputs, outputs=outputs) model.summary() Y-Network y-network\ub97c \ud65c\uc6a9\ud558\uba74 mlp\ubaa8\ub378\uacfc cnn\ubaa8\ub378\uc744 \ud569\uccd0\uc11c \uc0ac\uc6a9\ud560 \uc218 \uc788\ub2e4. \uc21c\ucc28\ud615\ubcf4\ub2e4 \ud568\uc218\ud615 api\uac00 \ud3b8\ud55c \uc774\uc720 \uc911 \ud558\ub098\ub2e4. \uc0ac\uc6a9\ud558\ub294 \ubc29\ubc95\ub3c4 \uc0dd\uac01\ubcf4\ub2e4 \uac04\ub2e8\ud558\ub2e4. for i in range(3): x = Conv2D(filters=filters, kernel_size=kernel_size, padding='same', activation='relu')(x) x = Dropout(dropout)(x) x = MaxPooling2D()(x) filters *= 2 \ubaa8\ub378 y\ub3c4 \ube44\uc2b7\ud558\uac8c \uc774\ub7f0\uc2dd\uc73c\ub85c \ub9cc\ub4e4\uc5b4\uc900\ub2e4. \uc774\ud6c4 \ub450 \ubaa8\ub378\uc744 \ud569\uce58\uace0, flatten, model\uc744 \ub9cc\ub4e0\ub2e4. y = concatenate([x, y]) y = Flatten()(y) y = Dropout(dropout)(y) outputs = Dense(num_labels, activation='softmax')(y) model = Model([left_inputs, right_inputs], outputs) plot_model(model, to_file='cnn-y-network.png', show_shapes=True) \uc774\ud6c4\uc5d0\ub294 \uc21c\ucc28\ud615 api\uc640 \uac19\uc774 comple, fit \ub4f1\ub4f1\uc758 \ud568\uc218\ub97c \uc0ac\uc6a9\ud558\uba74 \ub41c\ub2e4.","title":"Functional Api & Y Network with Keras"},{"location":"deeplearning/Functional Api & Y-Network with Keras/#functional-api-y-network-with-keras","text":"Date : 2019/11/17 Ref : \ucf00\ub77c\uc2a4\ub85c \uad6c\ud604\ud558\ub294 \uace0\uae09 \ub525\ub7ec\ub2dd \uc54c\uace0\ub9ac\uc998 [chapter 2]","title":"Functional Api &amp; Y-Network with Keras"},{"location":"deeplearning/Functional Api & Y-Network with Keras/#functional-api","text":"input\ub808\uc774\uc5b4\ub97c \ub530\ub85c \uac00\uc838\uc640\uc900\ub2e4. from keras.layers import Input \uc21c\ucc28\ud615\uacfc\ub294 \ucf54\ub4dc\uac00 \uc870\uae08\uc529 \ub2e4\ub974\ub2e4. \ud6c4\uc5d0 \ud655\uc7a5\uc131\uc744 \uace0\ub824\ud558\uc5ec \ud568\uc218\ud615\uc73c\ub85c \ucf00\ub77c\uc2a4 \ubaa8\ub378\uc744 \ub9cc\ub4dc\ub294 \uc5f0\uc2b5\uc744 \ud558\uc790. inputs = Input(shape=input_shape) y = Conv2D(filters=filters, kernel_size=kernel_size, activation='relu')(inputs) y = MaxPooling2D()(y) y = Conv2D(filters=filters, kernel_size=kernel_size, activation='relu')(y) y = MaxPooling2D()(y) y = Conv2D(filters=filters, kernel_size=kernel_size, activation='relu')(y) y = Flatten()(y) y = Dropout(dropout)(y) outputs = Dense(num_labels, activation='softmax')(y) model = Model(inputs=inputs, outputs=outputs) model.summary()","title":"functional api"},{"location":"deeplearning/Functional Api & Y-Network with Keras/#y-network","text":"y-network\ub97c \ud65c\uc6a9\ud558\uba74 mlp\ubaa8\ub378\uacfc cnn\ubaa8\ub378\uc744 \ud569\uccd0\uc11c \uc0ac\uc6a9\ud560 \uc218 \uc788\ub2e4. \uc21c\ucc28\ud615\ubcf4\ub2e4 \ud568\uc218\ud615 api\uac00 \ud3b8\ud55c \uc774\uc720 \uc911 \ud558\ub098\ub2e4. \uc0ac\uc6a9\ud558\ub294 \ubc29\ubc95\ub3c4 \uc0dd\uac01\ubcf4\ub2e4 \uac04\ub2e8\ud558\ub2e4. for i in range(3): x = Conv2D(filters=filters, kernel_size=kernel_size, padding='same', activation='relu')(x) x = Dropout(dropout)(x) x = MaxPooling2D()(x) filters *= 2 \ubaa8\ub378 y\ub3c4 \ube44\uc2b7\ud558\uac8c \uc774\ub7f0\uc2dd\uc73c\ub85c \ub9cc\ub4e4\uc5b4\uc900\ub2e4. \uc774\ud6c4 \ub450 \ubaa8\ub378\uc744 \ud569\uce58\uace0, flatten, model\uc744 \ub9cc\ub4e0\ub2e4. y = concatenate([x, y]) y = Flatten()(y) y = Dropout(dropout)(y) outputs = Dense(num_labels, activation='softmax')(y) model = Model([left_inputs, right_inputs], outputs) plot_model(model, to_file='cnn-y-network.png', show_shapes=True) \uc774\ud6c4\uc5d0\ub294 \uc21c\ucc28\ud615 api\uc640 \uac19\uc774 comple, fit \ub4f1\ub4f1\uc758 \ud568\uc218\ub97c \uc0ac\uc6a9\ud558\uba74 \ub41c\ub2e4.","title":"Y-Network"},{"location":"deeplearning/Mnist with mlp, cnn and rnn/","text":"Mnist with mlp, cnn and rnn Date : 2019/11/17 Ref : \ucf00\ub77c\uc2a4\ub85c \uad6c\ud604\ud558\ub294 \uace0\uae09 \ub525\ub7ec\ub2dd \uc54c\uace0\ub9ac\uc998 [chapter 1] dense\ub808\uc774\uc5b4\uc640 conv, simpleRnn\ub808\uc774\uc5b4\uc5d0\uc11c \uc694\uad6c\ud558\ub294 input shape\uc774 \uac01\uac01 \ub2e4\ub974\uae30 \ub54c\ubb38\uc5d0, \ub808\uc774\uc5b4\uc5d0 \ub9de\uac8c \ub370\uc774\ud130\uc758 shape\uc744 \ubcc0\uacbd\ud574\uc8fc\uc5b4\uc57c \ud55c\ub2e4. mnist\uc758 \uc774\ubbf8\uc9c0 \ud06c\uae30\ub294 28*28\uc774\ub2e4. mlp input shape 28 * 28 \ud06c\uae30\uc758 60000\uc7a5 \uc774\ubbf8\uc9c0[ (60000, 28, 28) ]\ub97c 784(\uc774\ubbf8\uc9c0\uc758 \ub113\uc774) * 60000 \uc7a5 \ud615\ud0dc[ (60000, 784) ]\ub85c \ub9cc\ub4e4\uc5b4\uc57c \ud55c\ub2e4. x_train = np.reshape(x_train, [-1, input_size]) x_test = np.reshape(x_test, [-1, input_size]) input_size = image_size * image_size model.add(Dense(hidden_units, input_dim=input_size)) cnn input shape cnn\uc740 input_shape=(n, m, 3) \uc758 \ud615\ud0dc\uac00 \ub418\uc5b4\uc57c \ud55c\ub2e4. \ub9c8\uc9c0\ub9c9 \uc778\uc790\ub294 rgb(3)\uc778\uc9c0, grayscale(1)\uc778\uc9c0\ub97c \ub73b\ud55c\ub2e4. x_train = np.reshape(x_train,[-1, image_size, image_size, 1]) x_test = np.reshape(x_test,[-1, image_size, image_size, 1]) input_shape = (image_size, image_size, 1) model.add(Conv2D(filters=filters, kernel_size=kernel_size, activation='relu', input_shape=input_shape)) rnn input shape rnn\uc740 \ucc45\uc758 \ud14d\uc2a4\ud2b8\uac00 \ub9e4\ub044\ub7fd\uc9c0 \uc54a\uace0, \uc124\uba85\ub3c4 \ubd80\uc871\ud574\uc11c \ube14\ub85c\uadf8 \ub97c \ucc38\uace0\ud588\ub2e4. rnn\uc740 (batch_size, timesteps, input_dim)\uc758 \ud615\ud0dc\uac00 \ub418\uc5b4\uc57c \ud55c\ub2e4. batch_size : \ub370\uc774\ud130 \uc778\uc2a4\ud134\uc2a4\uc758 \uac2f\uc218 timesteps : \uc778\ud48b \uc2dc\ud000\uc2a4\uc758 \uac2f\uc218 # input_length input_dim : \uac01 \uc778\ud48b \uc2dc\ud000\uc2a4\uc758 \ucc28\uc6d0 # \uc785\ub825\uc758 \ud06c\uae30 X_train = np.reshape(x_train,[-1, image_size, image_size]) input_shape = (image_size, image_size) model.add(SimpleRNN(units=units, dropout=dropout, input_shape=input_shape)) # input shape (timesteps(28), input_dim(28)) return_sequences : \ucd9c\ub825 \uc2dc\ud000\uc2a4\uc5d0\uc11c \ub9c8\uc9c0\ub9c9 \ucd9c\ub825\uc744 \ubc18\ud658\ud560\uc9c0 \ub610\ub294 \uc804\uccb4 \uc2dc\ud000\uc2a4\ub97c \ubc18\ud658\ud560\uc9c0 \uc5ec\ubd80 from keras.layers import Input inputs = Input(shape=(28,28)) rnn = SimpleRNN(50, return_sequences = True)(inputs) # rnn.shape (?, ?, 50) rnn = SimpleRNN(50, return_sequences = False)(inputs) # rnn.shape (?, 50)","title":"Mnist with mlp, cnn and rnn"},{"location":"deeplearning/Mnist with mlp, cnn and rnn/#mnist-with-mlp-cnn-and-rnn","text":"Date : 2019/11/17 Ref : \ucf00\ub77c\uc2a4\ub85c \uad6c\ud604\ud558\ub294 \uace0\uae09 \ub525\ub7ec\ub2dd \uc54c\uace0\ub9ac\uc998 [chapter 1] dense\ub808\uc774\uc5b4\uc640 conv, simpleRnn\ub808\uc774\uc5b4\uc5d0\uc11c \uc694\uad6c\ud558\ub294 input shape\uc774 \uac01\uac01 \ub2e4\ub974\uae30 \ub54c\ubb38\uc5d0, \ub808\uc774\uc5b4\uc5d0 \ub9de\uac8c \ub370\uc774\ud130\uc758 shape\uc744 \ubcc0\uacbd\ud574\uc8fc\uc5b4\uc57c \ud55c\ub2e4. mnist\uc758 \uc774\ubbf8\uc9c0 \ud06c\uae30\ub294 28*28\uc774\ub2e4.","title":"Mnist with mlp, cnn and rnn"},{"location":"deeplearning/Mnist with mlp, cnn and rnn/#mlp-input-shape","text":"28 * 28 \ud06c\uae30\uc758 60000\uc7a5 \uc774\ubbf8\uc9c0[ (60000, 28, 28) ]\ub97c 784(\uc774\ubbf8\uc9c0\uc758 \ub113\uc774) * 60000 \uc7a5 \ud615\ud0dc[ (60000, 784) ]\ub85c \ub9cc\ub4e4\uc5b4\uc57c \ud55c\ub2e4. x_train = np.reshape(x_train, [-1, input_size]) x_test = np.reshape(x_test, [-1, input_size]) input_size = image_size * image_size model.add(Dense(hidden_units, input_dim=input_size))","title":"mlp input shape"},{"location":"deeplearning/Mnist with mlp, cnn and rnn/#cnn-input-shape","text":"cnn\uc740 input_shape=(n, m, 3) \uc758 \ud615\ud0dc\uac00 \ub418\uc5b4\uc57c \ud55c\ub2e4. \ub9c8\uc9c0\ub9c9 \uc778\uc790\ub294 rgb(3)\uc778\uc9c0, grayscale(1)\uc778\uc9c0\ub97c \ub73b\ud55c\ub2e4. x_train = np.reshape(x_train,[-1, image_size, image_size, 1]) x_test = np.reshape(x_test,[-1, image_size, image_size, 1]) input_shape = (image_size, image_size, 1) model.add(Conv2D(filters=filters, kernel_size=kernel_size, activation='relu', input_shape=input_shape))","title":"cnn input shape"},{"location":"deeplearning/Mnist with mlp, cnn and rnn/#rnn-input-shape","text":"rnn\uc740 \ucc45\uc758 \ud14d\uc2a4\ud2b8\uac00 \ub9e4\ub044\ub7fd\uc9c0 \uc54a\uace0, \uc124\uba85\ub3c4 \ubd80\uc871\ud574\uc11c \ube14\ub85c\uadf8 \ub97c \ucc38\uace0\ud588\ub2e4. rnn\uc740 (batch_size, timesteps, input_dim)\uc758 \ud615\ud0dc\uac00 \ub418\uc5b4\uc57c \ud55c\ub2e4. batch_size : \ub370\uc774\ud130 \uc778\uc2a4\ud134\uc2a4\uc758 \uac2f\uc218 timesteps : \uc778\ud48b \uc2dc\ud000\uc2a4\uc758 \uac2f\uc218 # input_length input_dim : \uac01 \uc778\ud48b \uc2dc\ud000\uc2a4\uc758 \ucc28\uc6d0 # \uc785\ub825\uc758 \ud06c\uae30 X_train = np.reshape(x_train,[-1, image_size, image_size]) input_shape = (image_size, image_size) model.add(SimpleRNN(units=units, dropout=dropout, input_shape=input_shape)) # input shape (timesteps(28), input_dim(28)) return_sequences : \ucd9c\ub825 \uc2dc\ud000\uc2a4\uc5d0\uc11c \ub9c8\uc9c0\ub9c9 \ucd9c\ub825\uc744 \ubc18\ud658\ud560\uc9c0 \ub610\ub294 \uc804\uccb4 \uc2dc\ud000\uc2a4\ub97c \ubc18\ud658\ud560\uc9c0 \uc5ec\ubd80 from keras.layers import Input inputs = Input(shape=(28,28)) rnn = SimpleRNN(50, return_sequences = True)(inputs) # rnn.shape (?, ?, 50) rnn = SimpleRNN(50, return_sequences = False)(inputs) # rnn.shape (?, 50)","title":"rnn input shape"},{"location":"deeplearning/ResNet/","text":"ResNet Date : 2019/11/18 Ref : \ucf00\ub77c\uc2a4\ub85c \uad6c\ud604\ud558\ub294 \uace0\uae09 \ub525\ub7ec\ub2dd \uc54c\uace0\ub9ac\uc998 [chapter 2], \ub370\uc774\ud130 \uc0ac\uc774\uc5b8\uc2a4 \uc2a4\ucfe8 , \ub77c\uc628 \ud53c\ud50c , ratsgo , rarena \uc77c\ubc18\uc801\uc73c\ub85c \uc2e0\uacbd\ub9dd\uc774 \uae4a\uc5b4\uc9c8 \uc218\ub85d gradient vanishing/gradient exploding \ubb38\uc81c\uac00 \ubc1c\uc0dd\ud55c\ub2e4. resnet\ub3c4 rnn\uc758 \uc9c4\uc601\uc758 lstm\ucc98\ub7fc \uc774\ub7ec\ud55c \ubb38\uc81c\ub97c \ud574\uacb0\ud55c\ub2e4. Mnist keras application\uc758 resnet50\uc744 \uc0ac\uc6a9\ud558\uc5ec mnost \ubd84\ub958\ubb38\uc81c\ub97c \ud480\uc5b4\ubcf4\uc790. \uc21c\ucc28\ud615 api\uac00 \uc544\ub2cc \ud568\uc218\ud615 api\ub97c \uc0ac\uc6a9\ud55c\ub2e4. \uba3c\uc800, \ub370\uc774\ud130\ub97c \uac00\uc838\uc640 \uc900\ub2e4. import numpy as np from keras.models import Sequential from keras.layers import Activation, Dense, Dropout, Input, BatchNormalization from keras.layers import Conv2D, MaxPooling2D, Flatten from keras.utils import to_categorical, plot_model from keras.datasets import mnist from keras.applications import ResNet50 from keras.models import Model (x_train, y_train), (x_test, y_test) = mnist.load_data() num_labels = len(np.unique(y_train)) y_train = to_categorical(y_train) y_test = to_categorical(y_test) \uc774\ubbf8\uc9c0\uc758 \ud06c\uae30\ub97c \ud655\uc778\ud558\uace0, \uc815\uaddc\ud654 \ud574\uc900\ub2e4. print(x_train.shape) print(y_train.shape) x_train = x_train.astype('float32') / 255 x_test = x_test.astype('float32') / 255 # (50000, 32, 32, 3) # (50000, 10) input = Input(shape=(28, 28, 1)) resnet = ResNet50(input_tensor=input, include_top=True, weights=None) x = resnet.output x = BatchNormalization()(x) x = Dense(num_labels,activation='softmax')(x) model = Model(input, x) model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']) model.fit(x_train, y_train, epochs=5, batch_size=64) loss, acc = model.evaluate(x_test, y_test, batch_size=64) print(\"\\nTest accuracy: %.1f%%\" % (100.0 * acc)) # Test accuracy: 98.1% \uae30\uc874 resnet50\ub808\uc774\uc5b4 include_top=true\ub97c \uc918\uc11c flatten\uc744 \ucd94\uac00\ud558\uc600\uace0, \uc774\ud6c4 \uc544\uc6c3\ud48b \uac12\uc744 \uc815\uaddc\ud654 \uc2dc\ud0a4\uace0 Dense\ub808\uc774\uc5b4\uc5d0\uc11c \ubd84\ub958\ud55c\ub2e4.","title":"ResNet"},{"location":"deeplearning/ResNet/#resnet","text":"Date : 2019/11/18 Ref : \ucf00\ub77c\uc2a4\ub85c \uad6c\ud604\ud558\ub294 \uace0\uae09 \ub525\ub7ec\ub2dd \uc54c\uace0\ub9ac\uc998 [chapter 2], \ub370\uc774\ud130 \uc0ac\uc774\uc5b8\uc2a4 \uc2a4\ucfe8 , \ub77c\uc628 \ud53c\ud50c , ratsgo , rarena \uc77c\ubc18\uc801\uc73c\ub85c \uc2e0\uacbd\ub9dd\uc774 \uae4a\uc5b4\uc9c8 \uc218\ub85d gradient vanishing/gradient exploding \ubb38\uc81c\uac00 \ubc1c\uc0dd\ud55c\ub2e4. resnet\ub3c4 rnn\uc758 \uc9c4\uc601\uc758 lstm\ucc98\ub7fc \uc774\ub7ec\ud55c \ubb38\uc81c\ub97c \ud574\uacb0\ud55c\ub2e4.","title":"ResNet"},{"location":"deeplearning/ResNet/#mnist","text":"keras application\uc758 resnet50\uc744 \uc0ac\uc6a9\ud558\uc5ec mnost \ubd84\ub958\ubb38\uc81c\ub97c \ud480\uc5b4\ubcf4\uc790. \uc21c\ucc28\ud615 api\uac00 \uc544\ub2cc \ud568\uc218\ud615 api\ub97c \uc0ac\uc6a9\ud55c\ub2e4. \uba3c\uc800, \ub370\uc774\ud130\ub97c \uac00\uc838\uc640 \uc900\ub2e4. import numpy as np from keras.models import Sequential from keras.layers import Activation, Dense, Dropout, Input, BatchNormalization from keras.layers import Conv2D, MaxPooling2D, Flatten from keras.utils import to_categorical, plot_model from keras.datasets import mnist from keras.applications import ResNet50 from keras.models import Model (x_train, y_train), (x_test, y_test) = mnist.load_data() num_labels = len(np.unique(y_train)) y_train = to_categorical(y_train) y_test = to_categorical(y_test) \uc774\ubbf8\uc9c0\uc758 \ud06c\uae30\ub97c \ud655\uc778\ud558\uace0, \uc815\uaddc\ud654 \ud574\uc900\ub2e4. print(x_train.shape) print(y_train.shape) x_train = x_train.astype('float32') / 255 x_test = x_test.astype('float32') / 255 # (50000, 32, 32, 3) # (50000, 10) input = Input(shape=(28, 28, 1)) resnet = ResNet50(input_tensor=input, include_top=True, weights=None) x = resnet.output x = BatchNormalization()(x) x = Dense(num_labels,activation='softmax')(x) model = Model(input, x) model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']) model.fit(x_train, y_train, epochs=5, batch_size=64) loss, acc = model.evaluate(x_test, y_test, batch_size=64) print(\"\\nTest accuracy: %.1f%%\" % (100.0 * acc)) # Test accuracy: 98.1% \uae30\uc874 resnet50\ub808\uc774\uc5b4 include_top=true\ub97c \uc918\uc11c flatten\uc744 \ucd94\uac00\ud558\uc600\uace0, \uc774\ud6c4 \uc544\uc6c3\ud48b \uac12\uc744 \uc815\uaddc\ud654 \uc2dc\ud0a4\uace0 Dense\ub808\uc774\uc5b4\uc5d0\uc11c \ubd84\ub958\ud55c\ub2e4.","title":"Mnist"},{"location":"deeplearning/keras mnist/","text":"keras example from __future__ import print_function import keras from keras.datasets import mnist from keras.models import Sequential from keras.layers import Dense, Dropout, Flatten from keras.layers import Conv2D, MaxPooling2D from keras import backend as K batch_size = 128 num_classes = 10 epochs = 12 # input image dimensions img_rows, img_cols = 28, 28 # the data, split between train and test sets (x_train, y_train), (x_test, y_test) = mnist.load_data() if K.image_data_format() == 'channels_first': x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols) x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols) input_shape = (1, img_rows, img_cols) else: x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1) x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1) input_shape = (img_rows, img_cols, 1) x_train = x_train.astype('float32') x_test = x_test.astype('float32') x_train /= 255 x_test /= 255 print('x_train shape:', x_train.shape) print(x_train.shape[0], 'train samples') print(x_test.shape[0], 'test samples') # convert class vectors to binary class matrices y_train = keras.utils.to_categorical(y_train, num_classes) y_test = keras.utils.to_categorical(y_test, num_classes) model = Sequential() model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape)) model.add(Conv2D(64, (3, 3), activation='relu')) model.add(MaxPooling2D(pool_size=(2, 2))) model.add(Dropout(0.25)) model.add(Flatten()) model.add(Dense(128, activation='relu')) model.add(Dropout(0.5)) model.add(Dense(num_classes, activation='softmax')) model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adadelta(), metrics=['accuracy']) model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_test, y_test)) score = model.evaluate(x_test, y_test, verbose=0) print('Test loss:', score[0]) print('Test accuracy:', score[1])","title":"Keras mnist"},{"location":"deeplearning/keras mnist/#keras-example","text":"from __future__ import print_function import keras from keras.datasets import mnist from keras.models import Sequential from keras.layers import Dense, Dropout, Flatten from keras.layers import Conv2D, MaxPooling2D from keras import backend as K batch_size = 128 num_classes = 10 epochs = 12 # input image dimensions img_rows, img_cols = 28, 28 # the data, split between train and test sets (x_train, y_train), (x_test, y_test) = mnist.load_data() if K.image_data_format() == 'channels_first': x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols) x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols) input_shape = (1, img_rows, img_cols) else: x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1) x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1) input_shape = (img_rows, img_cols, 1) x_train = x_train.astype('float32') x_test = x_test.astype('float32') x_train /= 255 x_test /= 255 print('x_train shape:', x_train.shape) print(x_train.shape[0], 'train samples') print(x_test.shape[0], 'test samples') # convert class vectors to binary class matrices y_train = keras.utils.to_categorical(y_train, num_classes) y_test = keras.utils.to_categorical(y_test, num_classes) model = Sequential() model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape)) model.add(Conv2D(64, (3, 3), activation='relu')) model.add(MaxPooling2D(pool_size=(2, 2))) model.add(Dropout(0.25)) model.add(Flatten()) model.add(Dense(128, activation='relu')) model.add(Dropout(0.5)) model.add(Dense(num_classes, activation='softmax')) model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adadelta(), metrics=['accuracy']) model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_test, y_test)) score = model.evaluate(x_test, y_test, verbose=0) print('Test loss:', score[0]) print('Test accuracy:', score[1])","title":"keras example"}]}